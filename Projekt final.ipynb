{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze and classify the quality of 3D meshes, I relied on several libraries. \n",
    "The trimesh library to process .obj 3D models and extract their geometric properties. \n",
    "For the classification itself, I used sklearn and tensorflow, which provided the tools to build and evaluate machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import trimesh\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section defines three functions for classifying the quality of 3D meshes based on specific geometric metrics:\n",
    "- by Aspect Ratio\n",
    "- by Height Ratio\n",
    "- by Average Triangle Area\n",
    "\n",
    "These functions assign a quality label (good, average, bad) to a 3D mesh based on specific metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classify quality based on aspect ratio.\n",
    "def classify_by_aspect_ratio(aspect_ratio):\n",
    "    \n",
    "    if aspect_ratio > 10:\n",
    "        return \"bad\"\n",
    "    elif 5 < aspect_ratio <= 10:\n",
    "        return \"average\"\n",
    "    else:\n",
    "        return \"good\"\n",
    "\n",
    "\n",
    "# Classify quality based on height ratio.\n",
    "def classify_by_height_ratio(height_ratio):\n",
    "\n",
    "    if height_ratio > 10:\n",
    "        return \"bad\"\n",
    "    elif 5 < height_ratio <= 10:\n",
    "        return \"average\"\n",
    "    else:\n",
    "        return \"good\"\n",
    "    \n",
    "\n",
    "\n",
    "# Classify quality based on average triangle area\n",
    "def classify_by_triangle_area(avg_area):\n",
    "\n",
    "    if avg_area < 0.01:\n",
    "        return \"bad\"\n",
    "    elif 0.01 <= avg_area <= 0.1:\n",
    "        return \"average\"\n",
    "    else:\n",
    "        return \"good\"\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function calculates the overall quality of a 3D mesh by analyzing geometric properties of its triangles.\n",
    "\n",
    "It computes three metrics:\n",
    "- aspect ratio, height ratio and average triangle area\n",
    "\n",
    "and uses them to classify the mesh's quality.\n",
    "The final quality is determined through majority voting based on these metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute quality based on multiple metrics\n",
    "def compute_quality(mesh):\n",
    "\n",
    "    aspect_ratios = []\n",
    "    height_ratios = []  \n",
    "    triangle_areas = []\n",
    "\n",
    "    for face in mesh.faces:\n",
    "        v0, v1, v2 = mesh.vertices[face]\n",
    "\n",
    "        # Compute edge lengths\n",
    "        edges = [\n",
    "            np.linalg.norm(v1 - v0),\n",
    "            np.linalg.norm(v2 - v1),\n",
    "            np.linalg.norm(v0 - v2),\n",
    "        ]\n",
    "        longest_edge = max(edges)\n",
    "        shortest_edge = min(edges)\n",
    "\n",
    "        # Triangle area using Heron's formula\n",
    "        s = sum(edges) / 2.0\n",
    "        area = np.sqrt(s * (s - edges[0]) * (s - edges[1]) * (s - edges[2]))\n",
    "        if area > 0:\n",
    "            triangle_areas.append(area)\n",
    "\n",
    "        # Compute aspect ratio\n",
    "        if shortest_edge > 0:\n",
    "            aspect_ratios.append(longest_edge / shortest_edge)\n",
    "\n",
    "        # Compute all heights and find the longest and shortest\n",
    "        heights = []\n",
    "        for edge in edges:\n",
    "            if edge > 0:  # Avoid division by zero\n",
    "                height = 2 * area / edge\n",
    "                heights.append(height)\n",
    "\n",
    "        if len(heights) == 3:  # Ensure all heights are valid\n",
    "            longest_height = max(heights)\n",
    "            shortest_height = min(heights)\n",
    "            if shortest_height > 0:  # Avoid division by zero \n",
    "                height_ratios.append(longest_height / shortest_height)\n",
    "\n",
    "    # Compute average metrics\n",
    "    avg_aspect_ratio = np.mean(aspect_ratios) if aspect_ratios else float('nan')\n",
    "    avg_height_ratio = np.mean(height_ratios) if height_ratios else float('nan')\n",
    "    avg_triangle_area = np.mean(triangle_areas) if triangle_areas else float('nan')\n",
    "\n",
    "    # Vote for quality\n",
    "    votes = [\n",
    "        classify_by_aspect_ratio(avg_aspect_ratio),\n",
    "        classify_by_height_ratio(avg_height_ratio),\n",
    "        classify_by_triangle_area(avg_triangle_area),\n",
    "    ]\n",
    "\n",
    "    # Majority voting\n",
    "    vote_counts = {vote: votes.count(vote) for vote in set(votes)}\n",
    "    most_common_vote = max(vote_counts, key=vote_counts.get)\n",
    "\n",
    "    # Section that decides on the quality in the event of a tie\n",
    "    if list(vote_counts.values()).count(vote_counts[most_common_vote]) > 1:\n",
    "        return \"average\"  # Default to average in case of a tie\n",
    "    return most_common_vote\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function loads a 3D mesh from a file using the trimesh library. It ensures that the loaded file is a valid 3D mesh and raises appropriate errors if the file cannot be loaded or is invalid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a mesh from a file using trimesh\n",
    "def load_mesh(file_path):\n",
    "\n",
    "    try:\n",
    "        mesh = trimesh.load(file_path)\n",
    "        if not isinstance(mesh, trimesh.Trimesh):\n",
    "            raise ValueError(\"Not a valid Trimesh object.\")\n",
    "        if len(mesh.vertices) == 0 or len(mesh.faces) == 0:\n",
    "            raise ValueError(\"Mesh has no vertices or faces.\")\n",
    "        return mesh\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error loading mesh from {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function converts a 3D mesh into fixed-size matrices. The function ensures the data is normalized, padded or truncated to meet the specified size limits for vertices and faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertion of mesh into fixed-size matrices.\n",
    "def extract_mesh_to_matrix(mesh, max_vertices=500000, max_faces=1000000):\n",
    "   \n",
    "    vertices = mesh.vertices\n",
    "    faces = mesh.faces\n",
    "\n",
    "    # Normalize vertices (center and scale)\n",
    "    vertices = vertices - np.mean(vertices, axis=0)\n",
    "    vertices = vertices / np.max(np.linalg.norm(vertices, axis=1))\n",
    "\n",
    "    # Pad or truncate vertices\n",
    "    if len(vertices) > max_vertices:\n",
    "        vertices = vertices[:max_vertices]\n",
    "    else:\n",
    "        vertices = np.pad(vertices, ((0, max_vertices - len(vertices)), (0, 0)), 'constant')\n",
    "\n",
    "    # Pad or truncate faces\n",
    "    if len(faces) > max_faces:\n",
    "        faces = faces[:max_faces]\n",
    "    else:\n",
    "        faces = np.pad(faces, ((0, max_faces - len(faces)), (0, 0)), 'constant')\n",
    "\n",
    "    # Flatten vertices and faces into a single array\n",
    "    matrix = np.hstack([vertices.flatten(), faces.flatten()])\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function processes all 3D meshes in a specified directory, computes quality metrics for each mesh, and organizes the data for further use. It uses previously defined functions (load_mesh, extract_mesh_to_matrix, and compute_quality) to handle each mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all meshes in the directory and compute quality metrics.\n",
    "def process_meshes(directory_path):\n",
    "  \n",
    "    mesh_data = []\n",
    "    for file_name in os.listdir(directory_path):\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        if file_name.lower().endswith('.obj'):\n",
    "            try:\n",
    "                mesh = load_mesh(file_path)\n",
    "                matrix = extract_mesh_to_matrix(mesh)\n",
    "\n",
    "                # Compute quality based on votes\n",
    "                quality_group = compute_quality(mesh)\n",
    "\n",
    "                mesh_data.append({\n",
    "                    \"file_name\": file_name,\n",
    "                    \"matrix\": matrix,\n",
    "                    \"quality_group\": quality_group\n",
    "                })\n",
    "                print(f\"Processed: {file_name} -> Quality: {quality_group}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {file_name}: {e}\")\n",
    "    return mesh_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function trains and evaluates a Random Forest Classifier on the processed mesh data. It predicts the quality group of each mesh (e.g., good, average, bad) based on the feature matrix extracted from the meshes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(mesh_data):\n",
    "    # Prepare dataset\n",
    "    X = np.array([data[\"matrix\"] for data in mesh_data])\n",
    "    y = np.array([data[\"quality_group\"] for data in mesh_data])\n",
    "\n",
    "    # Encode labels to numeric values\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    # Splitting data into training/testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train Random Forest Classifier \n",
    "    rf_clf = RandomForestClassifier(random_state=42)\n",
    "    rf_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Test Random Forest Classifier\n",
    "    rf_pred = rf_clf.predict(X_test)\n",
    "    print(\"\\nRandom Forest Classification Report:\")\n",
    "    print(classification_report(y_test, rf_pred, target_names=label_encoder.classes_))\n",
    "    rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "    print(f\"Random Forest Test Accuracy: {rf_accuracy:.2f}\")\n",
    "\n",
    "    return rf_clf, label_encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function trains a neural network to classify the quality of 3D meshes. It uses PCA to reduce the dimensionality of the input data. The network uses progressively smaller dense layers with dropout to prevent overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(mesh_data, n_components=138, batch_size=32, epochs=20):\n",
    "    # Prepare dataset\n",
    "    X = np.array([data[\"matrix\"] for data in mesh_data], dtype=np.float32)\n",
    "    y = np.array([data[\"quality_group\"] for data in mesh_data])\n",
    "\n",
    "    # Dimensionality reduction using PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_reduced = pca.fit_transform(X)\n",
    "\n",
    "    # Encode labels to numeric values\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    # Splitting data into training/testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_reduced, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Neural Network Architecture\n",
    "    nn_model = Sequential([\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.4),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(len(label_encoder.classes_), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Training and tracking of the model\n",
    "    history = nn_model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Final test evaluation\n",
    "    nn_loss, nn_accuracy = nn_model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"\\nFinal Neural Network Test Accuracy: {nn_accuracy:.2f}\")\n",
    "\n",
    "    return nn_model, label_encoder, pca, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section contains the code that processes the meshes from the given directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 5. American Gothic by Grant Wood.obj -> Quality: average\n",
      "Processed: AK47.obj -> Quality: bad\n",
      "Processed: Ammo_Box.obj -> Quality: bad\n",
      "Processed: AT_MINE.obj -> Quality: bad\n",
      "Processed: BaseballBat.obj -> Quality: bad\n",
      "Processed: BathroomSink.obj -> Quality: average\n",
      "Processed: Bear.OBJ -> Quality: good\n",
      "Processed: BearTrap.obj -> Quality: bad\n",
      "Processed: Boxer.obj -> Quality: average\n",
      "Processed: C4.obj -> Quality: bad\n",
      "Processed: Ceiling_Lamp.obj -> Quality: average\n",
      "Processed: Christ the Redeemer.obj -> Quality: good\n",
      "Processed: Claymore.obj -> Quality: bad\n",
      "Processed: Closet.obj -> Quality: average\n",
      "Processed: Coffee_Table.obj -> Quality: bad\n",
      "Processed: Combat_Knife.obj -> Quality: average\n",
      "Processed: Console.obj -> Quality: bad\n",
      "Processed: Container.obj -> Quality: bad\n",
      "Processed: Crate.obj -> Quality: average\n",
      "Processed: Cupboard.obj -> Quality: average\n",
      "Processed: Deer.obj -> Quality: good\n",
      "Processed: Door01.obj -> Quality: bad\n",
      "Processed: Drone.obj -> Quality: average\n",
      "Processed: Dynamite.obj -> Quality: average\n",
      "Processed: ElectricalBox.obj -> Quality: bad\n",
      "Processed: FireAxe.obj -> Quality: average\n",
      "Processed: Flashbang.obj -> Quality: average\n",
      "Processed: Flashlight.obj -> Quality: good\n",
      "Processed: FlatScreenTV.obj -> Quality: bad\n",
      "Processed: Fluorescent_Lamp.obj -> Quality: average\n",
      "Processed: FragGrenade.obj -> Quality: average\n",
      "Processed: Giraffe.obj -> Quality: good\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_11912\\4174747390.py:22: RuntimeWarning: invalid value encountered in sqrt\n",
      "  area = np.sqrt(s * (s - edges[0]) * (s - edges[1]) * (s - edges[2]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: Grease_Gun.obj -> Quality: average\n",
      "Processed: hand1.OBJ -> Quality: good\n",
      "Processed: happy_budha-original.obj -> Quality: average\n",
      "Processed: IKEA_BESTA_1.obj -> Quality: bad\n",
      "Processed: IKEA_BILLY_1.obj -> Quality: bad\n",
      "Processed: IKEA_BILLY_2.obj -> Quality: bad\n",
      "Processed: IKEA_BILLY_3.obj -> Quality: bad\n",
      "Processed: IKEA_BILLY_4.obj -> Quality: bad\n",
      "Processed: IKEA_BILLY_5.obj -> Quality: bad\n",
      "Processed: IKEA_BJORKUDDEN_1.obj -> Quality: bad\n",
      "Processed: IKEA_BRIMNES_1.obj -> Quality: bad\n",
      "Processed: IKEA_BRIMNES_2.obj -> Quality: bad\n",
      "Processed: IKEA_EKTORP_2.obj -> Quality: bad\n",
      "Processed: IKEA_EKTORP_3.obj -> Quality: bad\n",
      "Processed: IKEA_EXPEDIT_2.obj -> Quality: average\n",
      "Processed: IKEA_EXPEDIT_3.obj -> Quality: bad\n",
      "Processed: IKEA_KAUSTBY.obj -> Quality: bad\n",
      "Processed: IKEA_LACK_1.obj -> Quality: average\n",
      "Processed: IKEA_LACK_2.obj -> Quality: average\n",
      "Processed: IKEA_LAIVA.obj -> Quality: bad\n",
      "Processed: IKEA_MANSTAD.obj -> Quality: bad\n",
      "Processed: IKEA_NORDEN_1.obj -> Quality: bad\n",
      "Processed: IKEA_NORDLI.obj -> Quality: bad\n",
      "Processed: IKEA_PAX_1.obj -> Quality: bad\n",
      "Processed: IKEA_PAX_4.obj -> Quality: bad\n",
      "Processed: IKEA_VIKA_1.obj -> Quality: bad\n",
      "Processed: Jesus on cross.obj -> Quality: good\n",
      "Processed: Katana.obj -> Quality: bad\n",
      "Processed: Klown.OBJ -> Quality: good\n",
      "Processed: Kunai.obj -> Quality: good\n",
      "Processed: Locker.obj -> Quality: average\n",
      "Processed: Luger.obj -> Quality: average\n",
      "Processed: Lumberjack.obj -> Quality: good\n",
      "Processed: M24_Grenade.obj -> Quality: average\n",
      "Processed: M4A1.obj -> Quality: average\n",
      "Processed: Machete.obj -> Quality: bad\n",
      "Processed: Madonna.obj -> Quality: bad\n",
      "Processed: Male.OBJ -> Quality: good\n",
      "Processed: Microphone.obj -> Quality: average\n",
      "Processed: Microwave.obj -> Quality: bad\n",
      "Processed: MilitaryFirstAidKit.obj -> Quality: average\n",
      "Processed: Molotov_Cocktail.obj -> Quality: average\n",
      "Processed: Monitor.obj -> Quality: bad\n",
      "Processed: NailBat.obj -> Quality: bad\n",
      "Processed: NAPOLEON_fix.OBJ -> Quality: good\n",
      "Processed: Nietzsche bust1.obj -> Quality: good\n",
      "Processed: Nuclear_Bomb.obj -> Quality: bad\n",
      "Processed: Oven.obj -> Quality: bad\n",
      "Processed: PalletTruck.obj -> Quality: average\n",
      "Processed: Pirate.obj -> Quality: good\n",
      "Processed: Police Riot Shield.obj -> Quality: good\n",
      "Processed: PoliceBaton.obj -> Quality: average\n",
      "Processed: Racing_Driver.obj -> Quality: good\n",
      "Processed: Rottweiler.obj -> Quality: good\n",
      "Processed: Saw.obj -> Quality: bad\n",
      "Processed: School of Athens.obj -> Quality: good\n",
      "Processed: ScifiChair.obj -> Quality: bad\n",
      "Processed: ScifiGenerator.obj -> Quality: average\n",
      "Processed: ScifiPistol.obj -> Quality: bad\n",
      "Processed: Scooter.obj -> Quality: average\n",
      "Processed: Scream 3D-bl.obj -> Quality: good\n",
      "Processed: Set of Futuristic Watches.obj -> Quality: good\n",
      "Processed: Set of Lollipops.obj -> Quality: bad\n",
      "Processed: Set of Rings.obj -> Quality: bad\n",
      "Processed: Set of Tropical Fruits.obj -> Quality: good\n",
      "Processed: Shotgun.obj -> Quality: bad\n",
      "Processed: SledgeHammer.obj -> Quality: bad\n",
      "Processed: Smoke_Grenade.obj -> Quality: average\n",
      "Processed: Sniper.obj -> Quality: average\n",
      "Processed: Solomon's Tample.obj -> Quality: bad\n",
      "Processed: Spade.obj -> Quality: bad\n",
      "Processed: Spartan.obj -> Quality: good\n",
      "Processed: Speaker.obj -> Quality: bad\n",
      "Processed: SS_01.obj -> Quality: good\n",
      "Processed: SS_02.obj -> Quality: good\n",
      "Processed: SS_03.obj -> Quality: good\n",
      "Processed: SS_04.obj -> Quality: good\n",
      "Processed: SS_05.obj -> Quality: good\n",
      "Processed: SS_06.obj -> Quality: good\n",
      "Processed: SS_07.obj -> Quality: good\n",
      "Processed: SS_08.obj -> Quality: good\n",
      "Processed: SS_09.obj -> Quality: good\n",
      "Processed: SS_1.obj -> Quality: good\n",
      "Processed: SS_10.obj -> Quality: good\n",
      "Processed: SS_11.obj -> Quality: good\n",
      "Processed: SS_12.obj -> Quality: good\n",
      "Processed: SS_13.obj -> Quality: good\n",
      "Processed: SS_2.obj -> Quality: good\n",
      "Processed: SS_3.obj -> Quality: good\n",
      "Processed: SS_4.obj -> Quality: good\n",
      "Processed: SS_5.obj -> Quality: good\n",
      "Processed: SS_6.obj -> Quality: good\n",
      "Processed: SS_7.obj -> Quality: good\n",
      "Processed: SS_8.obj -> Quality: good\n",
      "Processed: StreetLight.obj -> Quality: average\n",
      "Processed: StunGun.obj -> Quality: average\n",
      "Processed: Suomi_KP.obj -> Quality: average\n",
      "Processed: Swan.obj -> Quality: good\n",
      "Processed: tetrahedron.obj -> Quality: good\n",
      "Processed: Toilet.obj -> Quality: average\n",
      "Processed: Tomahawk.obj -> Quality: average\n",
      "Processed: Tomahawk_Modern.obj -> Quality: average\n",
      "Processed: torus.obj -> Quality: good\n",
      "Processed: Vice.obj -> Quality: bad\n",
      "Processed: Viking.obj -> Quality: good\n",
      "Processed: Wall_Clock.obj -> Quality: bad\n",
      "Processed: Wizard.obj -> Quality: good\n",
      "Processed: Wrench.obj -> Quality: average\n"
     ]
    }
   ],
   "source": [
    "directory_path = \"3d meshe\"  # Path to directory with meshes\n",
    "\n",
    "# Process meshes\n",
    "mesh_data = process_meshes(directory_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A code for starting training a Random Forest model on mesh data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     average       0.67      0.67      0.67         6\n",
      "         bad       0.70      0.88      0.78         8\n",
      "        good       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.82        28\n",
      "   macro avg       0.79      0.80      0.79        28\n",
      "weighted avg       0.84      0.82      0.83        28\n",
      "\n",
      "Random Forest Test Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "if len(mesh_data) > 0:\n",
    "    rf_clf, label_encoder_1 = train_random_forest(mesh_data)\n",
    "else:\n",
    "    print(\"No valid meshes to process.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A code for starting training a Neural Network model on mesh data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.3424 - loss: 3269662.0000 - val_accuracy: 0.4286 - val_loss: 1575136.3750\n",
      "Epoch 2/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4092 - loss: 2401079.5000 - val_accuracy: 0.3929 - val_loss: 616045.5000\n",
      "Epoch 3/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3613 - loss: 3709973.7500 - val_accuracy: 0.5000 - val_loss: 107906.3828\n",
      "Epoch 4/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4320 - loss: 2106746.2500 - val_accuracy: 0.3929 - val_loss: 203259.9844\n",
      "Epoch 5/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4774 - loss: 2907929.5000 - val_accuracy: 0.3929 - val_loss: 293655.7188\n",
      "Epoch 6/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4372 - loss: 721755.1250 - val_accuracy: 0.4286 - val_loss: 157220.5938\n",
      "Epoch 7/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4549 - loss: 754321.5625 - val_accuracy: 0.4286 - val_loss: 180560.2500\n",
      "Epoch 8/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3999 - loss: 633665.6250 - val_accuracy: 0.5000 - val_loss: 186783.3281\n",
      "Epoch 9/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4927 - loss: 1856584.2500 - val_accuracy: 0.5000 - val_loss: 194467.1094\n",
      "Epoch 10/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5259 - loss: 762022.5000 - val_accuracy: 0.5000 - val_loss: 135763.9688\n",
      "Epoch 11/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4060 - loss: 690885.5000 - val_accuracy: 0.4286 - val_loss: 156262.7500\n",
      "Epoch 12/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3615 - loss: 1515082.5000 - val_accuracy: 0.4286 - val_loss: 189254.7344\n",
      "Epoch 13/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4561 - loss: 381533.0312 - val_accuracy: 0.4286 - val_loss: 92050.5391\n",
      "Epoch 14/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4287 - loss: 1053595.8750 - val_accuracy: 0.6786 - val_loss: 110464.2734\n",
      "Epoch 15/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4766 - loss: 519089.6562 - val_accuracy: 0.6786 - val_loss: 102899.5000\n",
      "Epoch 16/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4330 - loss: 2647603.0000 - val_accuracy: 0.7143 - val_loss: 106054.0703\n",
      "Epoch 17/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4899 - loss: 637824.1250 - val_accuracy: 0.7143 - val_loss: 113481.2109\n",
      "Epoch 18/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5079 - loss: 301458.0938 - val_accuracy: 0.7143 - val_loss: 103972.9609\n",
      "Epoch 19/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5503 - loss: 922581.4375 - val_accuracy: 0.7143 - val_loss: 85992.9453\n",
      "Epoch 20/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5454 - loss: 2686056.5000 - val_accuracy: 0.7143 - val_loss: 99499.4453\n",
      "\n",
      "Final Neural Network Test Accuracy: 0.71\n"
     ]
    }
   ],
   "source": [
    "if len(mesh_data) > 0:\n",
    "    nn_model, label_encoder_2, pca, history= train_neural_network(mesh_data)\n",
    "else:\n",
    "    print(\"No valid meshes to process.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A small example of how the quality of 3d meshes can be predicted with trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: Doctor.obj -> Quality: good\n",
      "Processed: Frog.obj -> Quality: good\n",
      "Processed: Saw.obj -> Quality: bad\n",
      "Processed: Squirrel.OBJ -> Quality: good\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n",
      "\n",
      "Object: Doctor.obj:\n",
      "  Real Quality: good\n",
      "  Predicted Quality (Random Forest): good\n",
      "  Predicted Quality (Neural Network): good\n",
      "\n",
      "Object: Frog.obj:\n",
      "  Real Quality: good\n",
      "  Predicted Quality (Random Forest): average\n",
      "  Predicted Quality (Neural Network): bad\n",
      "\n",
      "Object: Saw.obj:\n",
      "  Real Quality: bad\n",
      "  Predicted Quality (Random Forest): bad\n",
      "  Predicted Quality (Neural Network): bad\n",
      "\n",
      "Object: Squirrel.OBJ:\n",
      "  Real Quality: good\n",
      "  Predicted Quality (Random Forest): good\n",
      "  Predicted Quality (Neural Network): good\n",
      "\n"
     ]
    }
   ],
   "source": [
    "directory = \"meshe na ukazku\"  # Directory containing meshes\n",
    "mesh_data_2 = process_meshes(directory)\n",
    "\n",
    "print()\n",
    "# Preparing the feature matrix, object names and real quality\n",
    "X = np.array([data[\"matrix\"] for data in mesh_data_2])\n",
    "names = [data[\"file_name\"] for data in mesh_data_2]\n",
    "real_qualities = [data[\"quality_group\"] for data in mesh_data_2]  \n",
    "\n",
    "\n",
    "# Prediction using the trained Random Forest model\n",
    "predicted_indices_rf = rf_clf.predict(X)\n",
    "predicted_labels_rf = label_encoder_1.inverse_transform(predicted_indices_rf)\n",
    "\n",
    "# Prediction using the trained Neural Network model\n",
    "predicted_probabilities_nn = nn_model.predict(pca.transform(X))\n",
    "predicted_indices_nn = np.argmax(predicted_probabilities_nn, axis=1)\n",
    "predicted_labels_nn = label_encoder_2.inverse_transform(predicted_indices_nn)\n",
    "\n",
    "print()\n",
    "# Print predictions \n",
    "for i in range(len(names)):\n",
    "    print(f\"Object: {names[i]}:\")\n",
    "    print(f\"  Real Quality: {real_qualities[i]}\")\n",
    "    print(f\"  Predicted Quality (Random Forest): {predicted_labels_rf[i]}\")\n",
    "    print(f\"  Predicted Quality (Neural Network): {predicted_labels_nn[i]}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
